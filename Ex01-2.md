# 演習 1. 2 : Azure OpenAI Studio への言語モデルのデプロイ

Azure OpenAI が提供する AI サービスを利用するには、Azure OpenAI Studio にモデルをデプロイする必要があります。

具体的な手順は以下のとおりです。

\[**手順**\]

1. 前の手順で作成した Azure OpenAI リソースの概要画面で、\[**Explore and deploy**\] ボックス内の \[**Go to Azure OpenAI Studio**\]ボタンをクリックします

    ![Open AI Studio](images/DeployModel_OpenAIStudio.png)

2. Azure OpenAI Studio が開かれるので、画面左のメニューバーから \[**デプロイ**\] をクリックします

    ![AOAI Stuido Deploy menu](images/AOAIStudio_menue_Deploy.png)

3. \[**モデル、アプリ、サービスのデプロイを管理する**\] 画面に遷移するので、同画面の \[モデル デプロイ\] タブ内の \[**+ モデルのデプロイ**\] ボタンをクリックし、表示されたドロップダウンメニューから \[**基本モデルをデプロイする**\] を選択します

    ![Deploy Model](images/AOAIStudio_deployModel.png)

4. \[**モデルを選択してください**\] ダイアログボックスが表示されるので、同ダイアログボックス画面左のモデルのリストから \[**gpt-4o-mini**\] を選択し、\[**確認**\] ボタンをクリックします

    ![Select deploy model](images/AOAIStudio_ChoseDeployModel.png)

5. \[**モデル gpt-4o-mini をデプロイする**\] 画面に遷移するので、同画面の \[**1 分あたりのトークンレート制限 (数千)**\] のスライダーコントロールを使用して **対応する 1 分あたりのトークン数 (TPM)** を **300K** より大きい値に設定します

    なお、この値は後から変更することができるので、利用中に制限を超えた場合はさらに大きい値に変更します

    ![Set RPM](images/AOAIStudio_deployModel02.png)

    その他の項目は既定のまま、\[**デプロイ**\] ボタンをクリックします

6. デプロイはすぐに完了し、デプロイしたモデルの概要画面が表示されるので、\[詳細\] タブ内の \[**プレイグランドで開く**\] をクリックします

    ![GPT model open with playground](images/Open_PlayGround_gpt.png)

7. \[**チャット プレイグランド**\] の画面が表示されるので、「こんにちは」等のメッセージを入力し、キーボードの \[**Enter**\] キーを押下してモデルが応答することを確認します

    ![Chat with GPT model](images/AOAIStudio_Playground_Chat.png)

ここまでの手順で、Azure OpenAI Studio に GPT-4 モデルがデプロイされ、チャットプレイグランドでの動作確認が完了しました。

<!--



\[**パラメーター**\] 画面の設定内容については、各ラベル右横にある \[**(!)**\] アイコンをクリックすると、そのパラメーターの説明が表示されるので確認してください。

![Parameter description](images/Open_PlayGround_gpt_parametar.png)


-->
<br>

## 次へ

👉 [**演習 1. 3 : 埋め込みモデルのデプロイ**](Ex01-3.md) 

<br>

<hr>

👈 [**演習 1. 1  : Azure ポータルから Open AI リソースを作成**](Ex01-1.md) 

🏚️ [README に戻る](README.md)