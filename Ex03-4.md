# 演習 3. 4 : RAG (Retrieval-Augmented Generation) の実装

言語モデルの知識を拡張する手法として、取得拡張生成(RAG : Retrieval-Augmented Generation) があります。

RAG は、言語モデルに情報検索機能を組み込むことで、独自のデータを追加し知識を拡張する方法です。

仕組みとしては、ユーザーからのメッセージを直接言語モデルに送るのではなく、その前処理として検索サービスを使用して関連する情報を検索します。関連する情報が見つかった場合には、ユーザーからの問い合わせに対し、検索結果をもとに回答を生成するように言語モデルに指示します。

![RAG : 検索結果に情報があった場合](images/RAG_Flow01.png)

検索結果にユーザーからの問い合わせに関する情報が見つからなかった場合には、言語モデルに直接問い合わせを送り、回答を生成します。

![RAG : 検索結果に情報がなかった場合](images/RAG_Flow02.png)

なお、RAG に使用する検索サービスはユーザーからのメッセージをそのまま検索に使用できる「自然言語検索」が可能なものでないと検索の前に複雑な処理が必要になるので注意が必要です。

<br>

## 検索方式について

データの検索方法は従来のキーワード検索、フルテキスト検索、ルールベース検索等々、さまざまな方式がありますがこの演習では Azure AI Search を使用してベクトル検索を行います。

ベクトル検索は、データを多次元のベクトル空間に埋め込んでベクトル間の距離を計算することで、データの類似性を判定する方式です。たとえば、猫と犬を埋め込むと、猫と犬が近くに存在していたり、他の何かが遠くに存在していたりというのをベクトル空間上で表現できます。

データのベクトル化には AI の埋め込み(エンベディング)モデルを使用することが一般的です。埋め込みモデルは、自然言語処理、画像処理、音声処理等々、様々な分野で使用されている AI モデルで、データをベクトルに変換する機能を持っています。

この演習では[演習 1. 3 : 埋め込みモデルのデプロイ](Ex01-3.md) でデプロイした text-embedding-ada-002 モデルを使用して、ベクトル化を行います。

![ベクトル化](images/vectorization.png)

<br>

## 演習の内容

この演習では、ベクトル検索を可能にするまでの手順を簡略化するためにRAG の検索サービスとして [演習 2. 3 : 独自データの追加](x02-3.md) で作成した Azure AI Search サービスのインスタンスと自動生成されたインデックスを使用します。 

[Azure AI Search](https://learn.microsoft.com/ja-jp/azure/search/search-what-is-azure-search) は検索用の [REST API](https://learn.microsoft.com/ja-jp/rest/api/searchservice/) を提供しておりアプリケーションのコードからさまざなま形式のセマンティック検索を行うことができます。

<br>

## 準備 1 : Azure AI Search インスタンスの情報取得 

作成済の Azure AI Search インスタンスから API を利用するために必要な以下の情報を取得します。

* エンドポイント
* API キー
* インデックス名

具体的な手順は以下のとおりです。

\[**手順**\]

1. Azure ポータルで、[演習 2. 3 : 独自データの追加](Ex02-3.md#%E6%BA%96%E5%82%99-2--azure-ai-search-%E3%82%B5%E3%83%BC%E3%83%93%E3%82%B9%E3%81%AE%E4%BD%9C%E6%88%90) で作成した Azure AI Search サービス インタンスのプロパティ画面を開きます

2. \[**概要**\] 画面が表示されていることを確認し、インスタンス名と \[**URL**\] の値をコピーしてメモ帳等に保存します

    ![Azure AI Search インスタンスのエンドポイント](images/AISearch-url.png)

3. 画面左の \[**キー**\] メニューをクリックしると、\[**API アクセス制御**\] 画面が表示されるので **管理者キーの管理** の \[**プライマリ管理者 キー**\] の値をコピーしてメモ帳等に保存します

    ![Azure AI Search インスタンスの API キー](images/AISearch-adminKey.png)

4. 画面左の \[**インデックス**\] メニューをクリックし、インデックスの一覧が表示されるので、作成済のインデックス名をコピーしてメモ帳等に保存します

    ![Azure AI Search インデックス名](images/AISearch-index.png)

ここまでの手順て Azure AI Search の API を使用するために必要な情報を取得しました。

<br>

## 準備 2 : 埋め込み(エンベディング)モデルの情報取得

ベクトル検索を行うためには、ユーザーが検索に使用する問い合わせメッセージをベクトル化する必要があります。これは検索エンジンがメッセージのベクトル データとインデックス内のベクトル データを比較し距離(Cosine 類似度)を測る必要があるためです。

そのため、問い合わせメッセージのベクトル化に使用する埋め込みモデルは Azure AI Search がベクトル インデックスを作成する際に使用したモデルと同じモデルである必要があります。

今回は [演習 3.2](Ex02-3.md#%E3%83%81%E3%83%A3%E3%83%83%E3%83%88-%E3%83%97%E3%83%AC%E3%82%A4%E3%82%B0%E3%83%A9%E3%83%B3%E3%83%89%E7%94%BB%E9%9D%A2%E3%81%8B%E3%82%89%E7%8B%AC%E8%87%AA%E3%81%AE%E3%83%87%E3%83%BC%E3%82%BF%E3%82%92%E8%BF%BD%E5%8A%A0%E3%81%99%E3%82%8B) で独自のデータを追加する際に埋め込みモデル text-embedding-ada-002 を使用しているので、同じモデルを使用します。

同モデルの以下の情報を取得しておきます。

* デプロイメント名
* エンドポイント
* API キー


具体的な手順は以下のとおりです。

\[**手順**\]

1. [**Azure OpenAI Studio**](https://oai.azure.com/resource/overview) にアクセスし、画面左上の \[**現在のリソース**\] ドロップダウンボックスでこのハンズオンで使用しているリソースが選択されていることを確認します

    ![Azure OpenAI Studio](images/AOAIStudio_Current.png)

2. デプロイ済のモデルの一覧が表示されるので、演習 2 タスク 3 でデプロイした埋め込みモデルの名前をクリックします

    ![デプロイした埋め込みモデルの選択](images/AOAIStudio_Choose_DeployedModel.png)

3. 選択したモデルのプロパティ画面に遷移し、\[**詳細**\] タブがアクティブなった状態で表示されるのでデプロイ名と \[**ターゲット URL**\] と \[**キー**\] の値をコピーしてメモ帳等に保存します 

    ![埋め込みモデルの詳細](images/AOAIStudio_Detail_DeployedEmbeddingModel.png)

ここまでの手順で埋め込みモデルの API を使用するために必要な情報を取得しました。

<br>

## タスク 4-1 : HTTP Client ツールによる問い合わせメッセージのベクトル化とベクトル検索

Azure OpenAI サービスの埋め込みモデルと、Azure AI Search の API 呼び出しを行う際にやり取りされるデータを確認するために Visual Studio Code の REST Client 拡張を使用してリクエストを送信し、レスポンスを確認します。

まず最初に問い合わせメッセージを埋め込みモデルを使用してベクトル化し、そのベクトルを Azure AI Search に送信して検索を行います。

>[!Important]
>Azure AI Search のインデックスの作成を [独自データの追加](Ex02-3.md)ではなく [演習 2. 3 - オプション : Azure AI Search インポート ウィザードを使用したインデックスの作成](https://github.com/osamum/AOAI-first-step-for-Developer/blob/main/Ex02-3-op1.md) の手順で行った場合は、この手順 5 で送信するデータの "**select**" の内容を "title,content,url" から `"title,chunk"` に、"**fields**" の内容を "contentVector" から `"text_vector"` に変更してください。

具体的な手順は以下のとおりです。

\[**手順**\]

1. 埋め込みモデルに問い合わせメッセージのテキストを送信してベクトルデータを取得します。
    
    この演習のタスク 1 の [**HTTP Client ツールによる呼び出しの確認**](#http-client-%E3%83%84%E3%83%BC%E3%83%AB%E3%81%AB%E3%82%88%E3%82%8B%E5%91%BC%E3%81%B3%E5%87%BA%E3%81%97%E3%81%AE%E7%A2%BA%E8%AA%8D) で作成した **helloML.http** ファイルを開きます

2. ファイルに以下の内容をコピーして貼り付け、`@embedding_endpoint` に前の手順でメモしておいた埋め込みモデルのエンドポイントを記述します

    ```http
    ### 問い合わせメッセージをベクトル化
    @embedding_endpoint=埋め込みモデルのエンドポイントを記述

    POST {{embedding_endpoint}} HTTP/1.1
    Content-Type: application/json
    api-key: {{apiKey}}

    {"input": "やまたのおろち製作所の所在地はどこですか?"}
    ```
    (※) api-key は言語モデルと同じもので大丈夫です

3. ファイルに記述されている **POST** の上に \[**Send Request**\] と表示されるのでクリックします

    ![REST Client でのリクエスト送信](images/vscode_sendRequest_embedding.png)

4. レスポンスされたデータ内の `"embedding` の配列の値をコピーしてメモ帳等に保存します

    ![埋め込みモデルのレスポンス](images/Respones_embeddingData.png)

    ここまでの手順で問い合わせメッセージをベクトル化し、ベクトルデータを取得することができました。

5. 取得したベクトルデータを使用して Azure AI Search ベクトル検索を行います

    **helloML.http** ファイルに以下の内容を追加し、コメントの内容にしたがい、これまでの手順でメモしておいた Azure AI Search のエンドポイント、インデックス名、管理者キーを記述します。また送信する JSON の `vectorQueries/[vector]` に前の手順でメモしておいたベクトルデータを貼り付けます

    ```http
    ### Azure AI Search でベクトル検索を実行
    @search-service-url=Azure AI Search のエンドポイントを記述
    @index-name=インデックス名を記述
    @admin-apiKey=Azure AI Search の管理者キーを記述

    POST {{search-service-url}}/indexes/{{index-name}}/docs/search?api-version=2024-07-01
    Content-Type: application/json
    api-key: {{admin-apiKey}}

    {
        "count": true,
        "select": "title,content,url",
        "top": 1,
        "vectorQueries": [
            {
                "kind": "vector",
                "vector": [
                    // ここにベクトルデータを貼り付け
                ],
                "exhaustive": true,
                "fields": "contentVector"
            }
        ]
    }
    ```

6. ファイルに記述されている **POST** の上に \[**Send Request**\] と表示されるのでクリックします

    ![REST Client でのベクトル検索](images/vscode_sendRequest_Search.png)

8. 検索結果が返ることを確認します

    ![ベクトル検索の結果](images/Respones_VectorSearchResult.png)

ここまでの手順で問い合わせメッセージをベクトル化し、そのベクトルデータを Azure AI Search に送信して検索を行うことができました。

なお、Azure AI Search のベクトル検索、検索の際のパラメーターなど、ベクトルクエリの詳細な作成方法については以下のドキュメントをご参照ください。

* [**Azure AI Search のベクトル**](https://learn.microsoft.com/ja-jp/azure/search/vector-search-overview)

* [**Azure AI Search でベクトル クエリを作成する**](https://learn.microsoft.com/ja-jp/azure/search/vector-search-how-to-query?tabs=query-2024-07-01%2Cbuiltin-portal)

<br>

## タスク 4-2 : チャットボット アプリに RAG の機能を追加


Azure OpenAI 埋め込みモデルと Azure AI Search のベクトル検索を使用して演習 3.2 で作成した[チャットボット アプリケーション](Ex03-2.md)に RAG の機能を追加します。

>[!Important]
>Azure AI Search のインデックスの作成を [独自データの追加](Ex02-3.md)ではなく [演習 2. 3 - オプション : Azure AI Search インポート ウィザードを使用したインデックスの作成](https://github.com/osamum/AOAI-first-step-for-Developer/blob/main/Ex02-3-op1.md) の手順で行った場合は、この手順 11 で貼り付ける関数 **searchWithVectorQuery** 内のコード **fields :** の値を \["contentVector"\] から `["text-vector"]` に変更してください。

具体的な手順は以下のとおりです。

\[**手順**\]

1. [演習 3.1](Ex03-1.md#%E3%82%BF%E3%82%B9%E3%82%AF-2-http-client-%E3%83%84%E3%83%BC%E3%83%AB%E3%81%AB%E3%82%88%E3%82%8B%E5%91%BC%E3%81%B3%E5%87%BA%E3%81%97%E3%81%AE%E7%A2%BA%E8%AA%8D) で作成したフォルダー **devPlayground** を Visual Studio Code で開きます

2. はじめにボットアプリケーションから呼び出される関数を定義するためのファイルを作成します

    Visual Studio Code の画面左のツリービューから **AOAI** フォルダーを右クリックし、表示されたコンテキストメニューから \[**New File**\] を選択して **rag.js** という名前のファイルを作成します
    
    ![rag.js ファイルの作成](images/vscode_newFile_lm.png)

3. 作成した **rag.js** ファイルが編集状態で Visual Studio Code に開かれるので、以下の内容をコピーして貼り付けます

    このコードは必要なライブラリの参照と、これまでに手順で設定した環境変数を読み込む処理を行行っています。

    なお、変数 `deploymentName` の値はメモしておいた埋め込みモデルのデプロイメント名に置き換えてください。

    ```javascript
    const { AzureOpenAI } = require("openai");
    //[PLACEHOLDER:require @azure/search-documents]

    const dotenv = require("dotenv");
    dotenv.config();

    const embedding_endpoint = process.env["AZURE_OPENAI_ENDPOINT"];
    const embedding_apiKey = process.env["AZURE_OPENAI_API_KEY"];
    const embedding_deployment = "埋め込みモデルのデプロイメント名を記述";
    const apiVersion = "2024-06-01"; 

    //[PLACEHOLDER: load AI search valiables]
    ```
4. 続けて以下のコードを貼り付けます

    このコードは埋め込みモデルのクライアントのインスタンスを生成するもので、その下の関数 `getEmbedding` は引数として渡されたテクストを埋め込みモデルに送信してベクトルデータを取得し返り値として返す関数です。

    ```javascript
    //埋め込みモデルのクライアントを作成
    const embeddingClient = new AzureOpenAI({embedding_endpoint,embedding_apiKey,apiVersion,deployment: embedding_deployment});
    //[PLACEHOLDER: new searchClient]

    //テキストをベクトルデータに変換する関数
    async function getEmbedding(text) {
        const embeddings = await embeddingClient.embeddings.create({ input: text, model: ''});
        return embeddings.data[0].embedding;
    }
    ```
5. 続けて結果を確認するための以下のコードを貼り付けます。

    ```JavaScript
    //[DELETE: after embedding test]
    getEmbedding('やまたのおろち製作所の所在地はどこですか？')
        .then(embedding => console.log(embedding));

    ```
    このコードは getEmbedding 関数を呼び出し、その結果をコンソールに出力するためだけのコードです。正常動作が確認できたら削除するかコメントアウトしてください。

    キーボードの \[**Ctrl**\] + \[**S**\] キーを押下して変更を保存します

6. **rag.js** に記述したコードが正しく動作するか、実行して確認します

    Visual Studio Code のターミナル画面で以下のコマンドを実行し、Azure OpenAI の埋め込みモデルからベクトルデータが返ることを確認します。

    ```bash
    node AOAI/rag.js
    ```
    ![rag.js : テキストのベクトル化確認](images/run_ragjs_enbedding.png)

    うまくいかない場合は、以下のサンプルコードを確認してください。

    * [検索メッセージのベクトル化のサンプル](samples/rag_0.js)

7. 正しく実行されることが確認されたら結果を確認するためのコードはコメントアウトするか削除します

    ```javascript
    //[DELETE: after embedding test]
    //getEmbedding('やまたのおろち製作所の所在地はどこですか？')
    //    .then(embedding => console.log(embedding));
    ```

    キーボードの \[**Ctrl**\] + \[**S**\] キーを押下して変更を保存します

8. Azure AI Search API を使用するための準備をします

    Visual Studio Code のターミナル画面で以下のコマンドを実行して、Azure AI Search のライブラリをインストールします

    ```bash
    npm install @azure/search-documents
    ```

9. **.env** ファイルを開き、以下の 2 つの設定を追加します

    変数それぞれにこれまでの手順でメモしておいた Azure AI Search のエンドポイントと管理者キーを設定してください。

    ```text
    SEARCH_ENDPOINT=Azure AI Search のエンドポイントを記述
    SEARCH_API_KEY=Azure AI Search の管理者キーを記述
    ```
    キーボードの \[**Ctrl**\] + \[**S**\] キーを押下して変更を保存します

10. ファイル **rag.js** を開き、上部のコメント `//[PLACEHOLDER:require @azure/search-documents]` を以下のコードに置き換えます

    ```javascript
    const { SearchClient, AzureKeyCredential } = require("@azure/search-documents");
    ```

    同様にコメント、`//[PLACEHOLDER: load AI search valiables]` を以下のコードに置き換えます。変数 `search_indexName` にはメモしておいた Azure AI Search のインデックス名を記述します

    ```javascript
    const search_endpoint = process.env["SEARCH_ENDPOINT"];
    const search_apiKey = process.env["SEARCH_API_KEY"];
    const search_indexName = 'ここにインデックス名を記述';

    //Azure AI Search のクライアントを作成
    const searchClient = new SearchClient(search_endpoint, search_indexName, new AzureKeyCredential(search_apiKey));
    ```
11. 次に以下のコードを追加します

    `findIndex` 関数はユーザーからの問い合わせメッセージを受け取り、そのメッセージを Azure AI Search で検索し、検索結果がスコア 8 以上の場合は、検索結果を付加して言語モデルに回答の生成を依頼するメッセージを返します。<!-- スコアが 8 未満の場合は、問い合わせメッセージをそのまま返します。-->

    `searchWithVectorQuery` 関数はベクトル化された問い合わせメッセージを Azure AI Search に送信して検索を行い、最も近いベクトルを持つドキュメントを返します。

    ```javascript
    //問い合わせメッセージを受け取って検索を実行す
    async function findIndex(queryText) {
        const thresholdScore = 5.8;
        const embedding = await getEmbedding(queryText);
        const result = await searchWithVectorQuery(embedding, queryText);

        //スコアがしきい値以上の場合は、検索結果を付加して言語モデルに回答の生成を依頼するメッセージを返す
        //意図した判断とならない場合は、console.log(result.score) でスコアを確認して thresholdScore の値を調整
        if (result != null && result.score >= thresholdScore) {
            return `以下の [question] の内容に対し、[content]の内容を使用して回答してください。ただし[question]に対し[content]の内容が回答としてあっていないと判断した場合は[content]の内容を使用しないでください\n\n[question]\n${queryText}\n\n[content]\n${result.document.content}`
        } else {
            return queryText;
        }    
    }

    // ベクトル化されたクエリを使用して検索を実行
    async function searchWithVectorQuery(vectorQuery, queryText) {
        const searchResults = await searchClient.search(queryText, {
            vector: {
                fields: ["contentVector"],
                kNearestNeighborsCount: 3,
                value: vectorQuery,
            },
        });
        for await (const result of searchResults.results) {
            // クエリベクトルに最も近いものを返す
            return result;
        }
    }
    ```
12. 続けて結果を確認するための以下のコードを貼り付けます。

    ```javascript
    //[DELETE: after search test]
    findIndex('やまたのおろち製作所の所在地はどこですか？')
        .then(result => console.log(result));
    ```

    キーボードの \[**Ctrl**\] + \[**S**\] キーを押下して変更を保存します

13. **rag.js** に記述したコードが正しく動作するか、実行して確認します
    
    Visual Studio Code のターミナル画面で以下のコマンドを実行し、Azure AI Search のベクトル検索の結果が返ることを確認します。    

    ```bash
    node AOAI/rag.js
    ```
    ![rag.js : ベクトル検索の確認](images/run_ragjs_search.png)

    また質問内容を以下のように変更すると、問い合わせメッセージがそのまま返されることを確認します。

    ```text
    秋葉原の名物はなんですか?
    ```

    キーボードの \[**Ctrl**\] + \[**C**\] キーを押下してプログラムを終了します。

    うまくいかない場合は、以下のサンプルコードを確認してください。

    * [ベクトル検索のサンプル](samples/rag_1.js)

14. **rag.js** のコードが正しく動作することが確認できたら、検証用の以下のコードを削除するかコメントアウトします。

    ```javascript
    //[DELETE: after search test]
    //findIndex('やまたのおろち製作所の所在地はどこですか？')
        //.then(result => console.log(result));
    ```
    キーボードの \[**Ctrl**\] + \[**S**\] キーを押下して変更を保存します

15. ファイル **rag.js** 内に記述した関数を外部から呼び出せるように以下のコードをファイルの一番最後に追加します

    ```javascript
    module.exports = { findIndex };
    ```

    キーボードの \[**Ctrl**\] + \[**S**\] キーを押下して変更を保存します。

16. 作成した **rag.js** ファイルの機能を使用してチャットボット アプリケーションに RAG の機能を実装します

    Visual Studio Code の画面左のツリービューから **consoleBot.js** ファイルを開き、ファイル上部のコメント `//[PLACEHOLDER:require rag.js]` を以下のコードに置き換えます

    ```javascript
    const rag = require('./AOAI/rag.js')
    //[PLACEHOLDER:require webSearch.js]
    ```

    続けてコメント `//[REPLACE: RAG Integration]` とその下のコードを以下のコードに置き換えます

    ```javascript
    console.log(`\nAI : ${await lm.sendMessage(await rag.findIndex(data.trim()))}`);
    ```
    キーボードの \[**Ctrl**\] + \[**S**\] キーを押下して変更を保存します

17. チャットボット アプリケーションを起動して、RAG の機能が正しく動作することを確認します

    Visual Studio Code のターミナル画面で以下のコマンドを実行します

    ```bash
    node consoleBot.js
    ```

    チャットボット アプリケーションが起動したら、挨拶や `現在の時刻を教えてください` 等、従来の機能を以下のように質問を入力して RAG の機能が正しく動作することを確認します

    ```text
    やまたのおろち製作所の所在地はどこですか?
    ```

    ![RAG のレスポンスの確認](images/rag_response_yamatano.png)

    キーボードの \[**Ctrl**\] + \[**C**\] キーを押下してプログラムを終了します。

ここまでの手順で、Azure OpenAI サービスの埋め込みモデルと Azure AI Search のベクトル検索を使用して RAG の機能をチャットボット アプリケーションに追加することができました。

<br>

## まとめ

この演習では言語モデルの知識を拡張する手段として RAG の機能を追加する方法を学びました。

RAG を使用すると外部の検索サービスを利用して手軽に知識を拡張することができます。また仕組みが複雑でないため様々なサービスと連携することができます。

### インデックスへのデータの追加について

Azure AI Search のインデックスへのデータの登録方法については複数の方法が用意されています。詳細については以下のリンクをご参照ください。

* [**Azure AI Search の検索インデックスにデータを読み込む**](https://learn.microsoft.com/ja-jp/azure/search/search-how-to-load-search-index?tabs=sdk-dotnet)

また、[演習 2. 3 - オプション : Azure AI Search インポート ウィザードを使用したインデックスの作成](Ex02-3-op1.md) の手順でインデックスを作成すると、手順の途中で定期的にデータをインポートするためのスケジュールを設定することができます。


### RAG の性能について

仕組み上、RAG の性能は検索サービスや、検索の方式、登録されているデータの品質に大きく依存します。

今回は手順の簡略化のために [Azure OpenAI On Your Data](https://learn.microsoft.com/ja-jp/azure/ai-services/openai/concepts/use-your-data?tabs=ai-search%2Ccopilot) の機能を利用してデータ分割、チャンク化、インデックス スキーマの作成、埋め込みなどの作業を自動で行っていますが、これらの作業は通常、登録するデータに合わせて最適化する必要があり、専門的な知識が必要です。

よって、今回作成されたインデックスでは Azure AI Search の性能を充分に引き出せていない可能性があります。

この演習は RAG の仕組みを説明するための簡易的なものでしたが、より本格的な RAG を構築するためのチュートリアルが用意されていまずので、この演習で興味を持たれた方はぜひ以下のリンクを使用して学習を継続してください。

* [**RAG ソリューションを構築する - Azure AI Search**](https://learn.microsoft.com/ja-jp/azure/search/tutorial-rag-build-solution)

### ベクトル検索を提供する Azure のサービス

この演習では Azure AI Search を使用してベクトル検索を行いましたが、Azure には Cosmos DB や SQL Database、PostgreSQL 等々、他にもベクトル検索をサポートするサービスが提供されています。

それぞれ機能的な特色があり、利用形態、価格などによって柔軟に選択することができます。

これらサービスの機能比較や選択方法については以下のリンクをご参照ください。

* [**ベクトル検索用の Azure サービスを選択する**](https://learn.microsoft.com/ja-jp/azure/architecture/guide/technology-choices/vector-search)


### RAG 以外の言語モデルの知識の拡張手段

言語モデルの知識を拡張する手段は RAG 以外の手段としては微調整(Fine-tuning) があります。

RAG が外部の知識ベースを利用するのに対し微調整はモデル自体を追加のデータセットで再訓練する手法です。

特定のタスクやドメインに対して対してモデルを最適化するのに適しているとされています。

また、トークンの節約や外部の知識ベースが利用できない場合にも有効です。

Azure OpenAI サービスにおける微調整の手法については以下のリンクをご参照ください。

* [**Azure OpenAI の微調整を使用する状況** - Azure AI Service](https://learn.microsoft.com/ja-jp/azure/ai-services/openai/concepts/fine-tuning-considerations)

* [**微調整でモデルをカスタマイズする** - Azure OpenAI](https://learn.microsoft.com/ja-jp/azure/ai-services/openai/how-to/fine-tuning?tabs=turbo%2Cpython-new&pivots=programming-language-studio)

<br>

## 次へ

👉 [**演習 3. 5 : 画像認識機能の追加**](Ex03-5.md)

<br>

<hr>

👈 [**演習 3. 3 : Function Calling 機能を使用した任意の関数の実行** ](Ex03-3.md)

🏚️ [README に戻る](README.md)
